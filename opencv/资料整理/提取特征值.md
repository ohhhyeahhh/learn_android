# opencv 人脸识别之特征提取

# 前言 #

人脸图像特征提取：人脸识别系统可使用的特征通常分为视觉特征、像素统计特征、人脸图像变换系数特征、人脸图像代数特征等。人脸特征提取就是针对人脸的某些特征进行的。人脸特征提取，也称人脸表征，它是对人脸进行特征建模的过程。人脸特征提取的方法归纳起来分为两大类：一种是基于知识的表征方法；另外一种是基于代数特征或统计学习的表征方法。

基于知识的表征方法主要是根据人脸器官的形状描述以及他们之间的距离特性来获得有助于人脸分类的特征数据，其特征分量通常包括特征点间的欧氏距离、曲率和角度等。人脸由眼睛、鼻子、嘴、下巴等局部构成，对这些局部和它们之间结构关系的几何描述，可作为识别人脸的重要特征，这些特征被称为几何特征。基于知识的人脸表征主要包括基于几何特征的方法和模板匹配法。

## 1. HOG 特征

    int DataPrepare::getImageHogFeature(Mat &img, vector<float> & descriptors, Size & size)
    {
    	if (img.data == NULL)
    	{
    		cout << "No exist" << endl;
    		return -1;
    	}
    	resize(img, img, size);
    	HOGDescriptor *hog = new HOGDescriptor(size, Size(16, 16), Size(4, 4), Size(8, 8), 9);
    	hog->compute(img, descriptors, Size(1, 1), Size(0, 0));
    	cout << "descriptors size is :" << descriptors.size() << endl;
    	return 0;
    }


## 2. Sift 特征

    int DataPrepare::getImageSiftFeature(cv::Mat &img, std::vector<float> & descriptors, cv::Size & size)
    {
    	if (img.data == NULL)
    	{
    		cout << "No exist" << endl;
    		return -1;
    	}
    	resize(img, img, size);
    	Ptr<Feature2D> sift = xfeatures2d::SIFT::create(SIFT_NUM, 3, 0.01, 80);
    	std::vector<KeyPoint> keypointsa;
    	keypointsa.clear();
    	Mat a;//特征点描述
    		  //sift->detectAndCompute(src, mask, keypointsa, a);//得到特征点和特征点描述
    	sift->detectAndCompute(img, Mat(), keypointsa, a);
     
    	cout << "a length is :" << a.rows << "  " << a.cols << "  " << a.channels() << endl;
    	a.reshape(1, SIFT_NUM * 128);
    	//cout << "a length is :" << a.rows << "  " << a.cols << "  " << a.channels() << endl;
    	cout << "descriptors shape is :" << descriptors.size() << endl;
    }


## 3. LBP 特征

（多种 LBP特征， lbp_normal, lbp_circle, 旋转不变,  计算旋转不变 + 等价LBP特征）

    int DataPrepare::getImageLBPFeature(Mat &img, vector<float> & descriptors, Size & size, int radias)
    {
    	if (img.data == NULL)
    	{
    		cout << "No exist" << endl;
    		return -1;
    	}
    	resize(img, img, Size(size.width + radias * 2, size.height + radias * 2));
    	Mat dst = Mat(img.rows - 2 * radias, img.cols - 2 * radias, CV_8UC1, Scalar(0));;
    	//lbp_normal(img, dst);
    	int neighbors = 8;
    	int range = pow(2, neighbors);
    	lbp_circle(img, dst, radias, neighbors);
     
     
    	//int * map = (int *)malloc(sizeof(int)* range);
    	////rotation_invariant_mapping(dst, range, neighbors, map);
    	//rotation_uniform_invariant_mapping(dst, range, neighbors, map);
     
    	lbp_to_feature(dst, descriptors, 256);
    	//cout << "descriptors is :" << descriptors.size() << "  "<< descriptors[0] << endl;
    	return 0;
    }
    void lbp_circle(Mat& src, Mat &dst, int radius, int neighbors)
    {
    	for (int n = 0; n < neighbors; n++)
    	{
    		// 采样点的计算
    		float x = static_cast<float>(-radius * sin(2.0*CV_PI*n / static_cast<float>(neighbors)));
    		float y = static_cast<float>(radius * cos(2.0*CV_PI*n / static_cast<float>(neighbors)));
    		// 上取整和下取整的值
    		int fx = static_cast<int>(floor(x));
    		int fy = static_cast<int>(floor(y));
    		int cx = static_cast<int>(ceil(x));
    		int cy = static_cast<int>(ceil(y));
    		// 小数部分
    		float ty = y - fy;
    		float tx = x - fx;
    		// 设置插值权重
    		float w1 = (1 - tx) * (1 - ty);
    		float w2 = tx * (1 - ty);
    		float w3 = (1 - tx) * ty;
    		float w4 = tx * ty;
    		// 循环处理图像数据
    		for (int i = radius; i < src.rows - radius; i++)
    		{
    			for (int j = radius; j < src.cols - radius; j++)
    			{
    				// 计算插值
    				float t = static_cast<float>(w1*src.at<uchar>(i + fy, j + fx) + w2*src.at<uchar>(i + fy, j + cx) + w3*src.at<uchar>(i + cy, j + fx) + w4*src.at<uchar>(i + cy, j + cx));
    				// 进行编码  当t>=src(i,j)的时候取1，并进行相应的移位    避免 精度 损失：std::abs(t - src.at<uchar>(i, j)) < std::numeric_limits<float>::epsilon())
    				dst.at<uchar>(i - radius, j - radius) += ((t > src.at<uchar>(i, j)) || (std::abs(t - src.at<uchar>(i, j)) < std::numeric_limits<float>::epsilon())) << n;
    			}
    		}
    	}
    }
    //旋转不变 Mapping  range = 2^neighbors
    void rotation_invariant_mapping(Mat & src, int range, int neighbors, int *Mapping)
    {
    	int newMax, rm, r;
    	int *tmpMap;
     
     
    	newMax = 0;
    	tmpMap = (int *)malloc(sizeof(int)*range);
    	memset(tmpMap, -1, sizeof(int)*range);
     
     
    	for (int i = 0; i < range; i++)
    	{
    		rm = i;
    		r = i;
    		for (int j = 0; j < neighbors - 1; j++)
    		{
    			//将r向左循环移动一位,当r超过num_sp位时，舍弃  
    			r = r << 1;
    			if (r > range - 1)
    			{
    				r = r - (range - 1);
    			}
    			if (r < rm)
    			{
    				rm = r;
    			}
    		}
    		if (tmpMap[rm] < 0)
    		{
    			tmpMap[rm] = newMax;
    			newMax++;
     
     
    		}
    		Mapping[i] = tmpMap[rm];
    	}
    	for (int i = 0; i < src.cols; i++)
    	{
    		for (int j = 0; j < src.rows; j++)
    		{
    			src.at<uchar>(i, j) = Mapping[src.at<uchar>(i, j)];
    		}
    	}
    	free(tmpMap);
    }
    int calc_sum(int r)
    {
    	int res_sum;
     
     
    	res_sum = 0;
    	while (r)
    	{
    		res_sum = res_sum + r % 2;
    		r /= 2;
    	}
    	return res_sum;
    }
    //计算旋转不变 + 等价LBP特征 
    void rotation_uniform_invariant_mapping(Mat & src, int range, int num_sp, int *Mapping)
    {
    	int numt, i, j, tem_xor;
     
     
    	numt = 0;
    	tem_xor = 0;
    	for (i = 0; i < range; i++)
    	{
    		j = i << 1;
    		if (j > range - 1)
    		{
    			j = j - (range - 1);
    		}
     
     
    		tem_xor = i ^ j;    // 异或  
    		numt = calc_sum(tem_xor);//计算异或结果中1的个数，即跳变个数  
     
     
    		if (numt <= 2)
    		{
    			Mapping[i] = calc_sum(i);
    		}
    		else {
    			Mapping[i] = num_sp + 1;
    		}
    	}
    	for (int i = 0; i < src.cols; i++)
    	{
    		for (int j = 0; j < src.rows; j++)
    		{
    			src.at<uchar>(i, j) = Mapping[src.at<uchar>(i, j)];
    		}
    	}
    }
    void lbp_normal(Mat& src, Mat &dst)
    {
    	// 循环处理图像数据
    	for (int i = 1; i < src.rows - 1; i++)
    	{
    		for (int j = 1; j < src.cols - 1; j++)
    		{
    			uchar tt = 0;
    			int tt1 = 0;
    			uchar u = src.at<uchar>(i, j);
    			if (src.at<uchar>(i - 1, j - 1) > u) { tt += 1 << tt1; }
    			tt1++;
    			if (src.at<uchar>(i - 1, j) > u) { tt += 1 << tt1; }
    			tt1++;
    			if (src.at<uchar>(i - 1, j + 1) > u) { tt += 1 << tt1; }
    			tt1++;
    			if (src.at<uchar>(i, j + 1) > u) { tt += 1 << tt1; }
    			tt1++;
    			if (src.at<uchar>(i + 1, j + 1) > u) { tt += 1 << tt1; }
    			tt1++;
    			if (src.at<uchar>(i + 1, j) > u) { tt += 1 << tt1; }
    			tt1++;
    			if (src.at<uchar>(i + 1, j - 1) > u) { tt += 1 << tt1; }
    			tt1++;
    			if (src.at<uchar>(i - 1, j) > u) { tt += 1 << tt1; }
    			tt1++;
    			dst.at<uchar>(i - 1, j - 1) = tt;
    		}
    	}
    }
    void lbp_to_feature(Mat & src, vector<float> &descriptors, int num)
    {
    	int rows = src.rows;
    	int cols = src.cols;
    	Rect block = Rect(0, 0, rows / 3, cols / 3);
    	Mat roi;
    	int fea[256] = { 0 };
    	for (int k = 0; k < 3; k++)
    	{
    		for (int n = 0; n < 3; n++)
    		{
    			block.x = k * rows / 3;
    			block.y = n * cols / 3;
    			roi = src(block);
    			fea[256] = { 0 };
    			for (int i = 0; i < roi.rows; i++)
    			{
    				for (int j = 0; j < roi.cols; j++)
    				{
    					fea[roi.at<uchar>(i, j)]++;
    				}
    			}
    			for (int i = 0; i < num; i++)
    			{
    				descriptors.push_back(fea[i] / (16 * 16.0));
    			}
    		}
    	}
	}

## 4. 原始 LBP

    //原始LBP特征计算
    template <typename _tp>
    void getOriginLBPFeature(InputArray _src,OutputArray _dst)
    {
        Mat src = _src.getMat();
        _dst.create(src.rows-2,src.cols-2,CV_8UC1);
        Mat dst = _dst.getMat();
        dst.setTo(0);
        for(int i=1;i<src.rows-1;i++)
        {
            for(int j=1;j<src.cols-1;j++)
            {
                _tp center = src.at<_tp>(i,j);
                unsigned char lbpCode = 0;
                lbpCode |= (src.at<_tp>(i-1,j-1) > center) << 7;
                lbpCode |= (src.at<_tp>(i-1,j  ) > center) << 6;
                lbpCode |= (src.at<_tp>(i-1,j+1) > center) << 5;
                lbpCode |= (src.at<_tp>(i  ,j+1) > center) << 4;
                lbpCode |= (src.at<_tp>(i+1,j+1) > center) << 3;
                lbpCode |= (src.at<_tp>(i+1,j  ) > center) << 2;
                lbpCode |= (src.at<_tp>(i+1,j-1) > center) << 1;
                lbpCode |= (src.at<_tp>(i  ,j-1) > center) << 0;
                dst.at<uchar>(i-1,j-1) = lbpCode;
            }
        }
    }


## 5. 圆形 LBP 特征 (Circular LBP or Extended LBP)

由于原始LBP特征使用的是固定邻域内的灰度值，因此当图像的尺度发生变化时，LBP特征的编码将会发生错误，LBP特征将不能正确的反映像素点周围的纹理信息，因此研究人员对其进行了改进[3]。基本的 LBP 算子的最大缺陷在于它只覆盖了一个固定半径范围内的小区域，这显然不能满足不同尺寸和频率纹理的需要。为了适应不同尺度的纹理特征，并达到灰度和旋转不变性的要求，Ojala 等对 LBP 算子进行了改进，将 3×3 邻域扩展到任意邻域，并用圆形邻域代替了正方形邻域，改进后的 LBP 算子允许在半径为 R 的圆形邻域内有任意多个像素点。


    //圆形LBP特征计算，这种方法适于理解，但在效率上存在问题，声明时默认neighbors=8
    template <typename _tp>
    void getCircularLBPFeature(InputArray _src,OutputArray _dst,int radius,int neighbors)
    {
        Mat src = _src.getMat();
        //LBP特征图像的行数和列数的计算要准确
        _dst.create(src.rows-2*radius,src.cols-2*radius,CV_8UC1);
        Mat dst = _dst.getMat();
        dst.setTo(0);
        //循环处理每个像素
        for(int i=radius;i<src.rows-radius;i++)
        {
            for(int j=radius;j<src.cols-radius;j++)
            {
                //获得中心像素点的灰度值
                _tp center = src.at<_tp>(i,j);
                unsigned char lbpCode = 0;
                for(int k=0;k<neighbors;k++)
                {
                    //根据公式计算第k个采样点的坐标，这个地方可以优化，不必每次都进行计算radius*cos，radius*sin
                    float x = i + static_cast<float>(radius * \
                        cos(2.0 * CV_PI * k / neighbors));
                    float y = j - static_cast<float>(radius * \
                        sin(2.0 * CV_PI * k / neighbors));
                    //根据取整结果进行双线性插值，得到第k个采样点的灰度值
     
                    //1.分别对x，y进行上下取整
                    int x1 = static_cast<int>(floor(x));
                    int x2 = static_cast<int>(ceil(x));
                    int y1 = static_cast<int>(floor(y));
                    int y2 = static_cast<int>(ceil(y));
     
                    //2.计算四个点(x1,y1),(x1,y2),(x2,y1),(x2,y2)的权重
                    //下面的权重计算方式有个问题，如果四个点都相等，则权重全为0，计算出来的插值为0
                    //float w1 = (x2-x)*(y2-y); //(x1,y1)
                    //float w2 = (x2-x)*(y-y1); //(x1,y2)
                    //float w3 = (x-x1)*(y2-y); //(x2,y1)
                    //float w4 = (x-x1)*(y-y1); //(x2,y2)
     
                    //将坐标映射到0-1之间
                    float tx = x - x1;
                    float ty = y - y1;
                    //根据0-1之间的x，y的权重计算公式计算权重
                    float w1 = (1-tx) * (1-ty);
                    float w2 =    tx  * (1-ty);
                    float w3 = (1-tx) *    ty;
                    float w4 =    tx  *    ty;
                    //3.根据双线性插值公式计算第k个采样点的灰度值
                    float neighbor = src.at<_tp>(x1,y1) * w1 + src.at<_tp>(x1,y2) *w2 \
                        + src.at<_tp>(x2,y1) * w3 +src.at<_tp>(x2,y2) *w4;
                    //通过比较获得LBP值，并按顺序排列起来
                    lbpCode |= (neighbor>center) <<(neighbors-k-1);
                }
                dst.at<uchar>(i-radius,j-radius) = lbpCode;
            }
        }
    }
    //圆形LBP特征计算，效率优化版本，声明时默认neighbors=8
    template <typename _tp>
    void getCircularLBPFeatureOptimization(InputArray _src,OutputArray _dst,int radius,int neighbors)
    {
        Mat src = _src.getMat();
        //LBP特征图像的行数和列数的计算要准确
        _dst.create(src.rows-2*radius,src.cols-2*radius,CV_8UC1);
        Mat dst = _dst.getMat();
        dst.setTo(0);
        for(int k=0;k<neighbors;k++)
        {
            //计算采样点对于中心点坐标的偏移量rx，ry
            float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));
            float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));
            //为双线性插值做准备
            //对采样点偏移量分别进行上下取整
            int x1 = static_cast<int>(floor(rx));
            int x2 = static_cast<int>(ceil(rx));
            int y1 = static_cast<int>(floor(ry));
            int y2 = static_cast<int>(ceil(ry));
            //将坐标偏移量映射到0-1之间
            float tx = rx - x1;
            float ty = ry - y1;
            //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关
            float w1 = (1-tx) * (1-ty);
            float w2 =    tx  * (1-ty);
            float w3 = (1-tx) *    ty;
            float w4 =    tx  *    ty;
            //循环处理每个像素
            for(int i=radius;i<src.rows-radius;i++)
            {
                for(int j=radius;j<src.cols-radius;j++)
                {
                    //获得中心像素点的灰度值
                    _tp center = src.at<_tp>(i,j);
                    //根据双线性插值公式计算第k个采样点的灰度值
                    float neighbor = src.at<_tp>(i+x1,j+y1) * w1 + src.at<_tp>(i+x1,j+y2) *w2 \
                        + src.at<_tp>(i+x2,j+y1) * w3 +src.at<_tp>(i+x2,j+y2) *w4;
                    //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得
                    dst.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);
                }
            }
        }
    }


## 6. 旋转不变 LBP 特征

从上面可以看出，上面的LBP特征具有灰度不变性，但还不具备旋转不变性，因此研究人员又在上面的基础上进行了扩展，提出了具有旋转不变性的LBP特征。首先不断的旋转圆形邻域内的LBP特征，根据选择得到一系列的LBP特征值，从这些LBP特征值选择LBP特征值最小的作为中心像素点的LBP特征。具体做法如下图所示:

    //旋转不变圆形LBP特征计算，声明时默认neighbors=8
    template <typename _tp>
    void getRotationInvariantLBPFeature(InputArray _src,OutputArray _dst,int radius,int neighbors)
    {
        Mat src = _src.getMat();
        //LBP特征图像的行数和列数的计算要准确
        _dst.create(src.rows-2*radius,src.cols-2*radius,CV_8UC1);
        Mat dst = _dst.getMat();
        dst.setTo(0);
        for(int k=0;k<neighbors;k++)
        {
            //计算采样点对于中心点坐标的偏移量rx，ry
            float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));
            float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));
            //为双线性插值做准备
            //对采样点偏移量分别进行上下取整
            int x1 = static_cast<int>(floor(rx));
            int x2 = static_cast<int>(ceil(rx));
            int y1 = static_cast<int>(floor(ry));
            int y2 = static_cast<int>(ceil(ry));
            //将坐标偏移量映射到0-1之间
            float tx = rx - x1;
            float ty = ry - y1;
            //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关
            float w1 = (1-tx) * (1-ty);
            float w2 =    tx  * (1-ty);
            float w3 = (1-tx) *    ty;
            float w4 =    tx  *    ty;
            //循环处理每个像素
            for(int i=radius;i<src.rows-radius;i++)
            {
                for(int j=radius;j<src.cols-radius;j++)
                {
                    //获得中心像素点的灰度值
                    _tp center = src.at<_tp>(i,j);
                    //根据双线性插值公式计算第k个采样点的灰度值
                    float neighbor = src.at<_tp>(i+x1,j+y1) * w1 + src.at<_tp>(i+x1,j+y2) *w2 \
                        + src.at<_tp>(i+x2,j+y1) * w3 +src.at<_tp>(i+x2,j+y2) *w4;
                    //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得
                    dst.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);
                }
            }
        }
        //进行旋转不变处理
        for(int i=0;i<dst.rows;i++)
        {
            for(int j=0;j<dst.cols;j++)
            {
                unsigned char currentValue = dst.at<uchar>(i,j);
                unsigned char minValue = currentValue;
                for(int k=1;k<neighbors;k++)
                {
        //循环左移
                    unsigned char temp = (currentValue>>(neighbors-k)) | (currentValue<<k);
                    if(temp < minValue)
                    {
                        minValue = temp;
                    }
                }
                dst.at<uchar>(i,j) = minValue;
            }
        }
    }


## 7. Uniform Pattern LBP 特征

Uniform Pattern，也被称为等价模式或均匀模式，由于一个LBP特征有多种不同的二进制形式，对于半径为R的圆形区域内含有P个采样点的LBP算子将会产生2P2P种模式。很显然，随着邻域集内采样点数的增加，二进制模式的种类是以指数形式增加的。例如：5×5邻域内20个采样点，有220220＝1,048,576种二进制模式。这么多的二进制模式不利于纹理的提取、分类、识别及存取。例如，将LBP算子用于纹理分类或人脸识别时，常采用LBP模式的统计直方图来表达图像的信息，而较多的模式种类将使得数据量过大，且直方图过于稀疏。因此，需要对原始的LBP模式进行降维，使得数据量减少的情况下能最好的表示图像的信息。 
为了解决二进制模式过多的问题，提高统计性，Ojala提出了采用一种“等价模式”(Uniform Pattern)来对LBP算子的模式种类进行降维。Ojala等认为，在实际图像中，绝大多数LBP模式最多只包含两次从1到0或从0到1的跳变。因此，Ojala将“等价模式”定义为：当某个LBP所对应的循环二进制数从0到1或从1到0最多有两次跳变时，该LBP所对应的二进制就称为一个等价模式类。如00000000(0次跳变)，00000111(只含一次从0到1的跳变)，10001111(先由1跳到0，再由0跳到1，共两次跳变)都是等价模式类。除等价模式类以外的模式都归为另一类，称为混合模式类，例如10010111(共四次跳变)。通过这样的改进，二进制模式的种类大大减少，而不会丢失任何信息。模式数量由原来的2P2P种减少为 P ( P-1)+2种，其中P表示邻域集内的采样点数。对于3×3邻域内8个采样点来说，二进制模式由原始的256种减少为58种，即：它把值分为59类，58个uniform pattern为一类，其它的所有值为第59类。这样直方图从原来的256维变成59维。这使得特征向量的维数更少，并且可以减少高频噪声带来的影响。 
具体实现：采样点数目为8个，即LBP特征值有28
28种，共256个值，正好对应灰度图像的0-255，因此原始的LBP特征图像是一幅正常的灰度图像，而等价模式LBP特征，根据0-1跳变次数，将这256个LBP特征值分为了59类，从跳变次数上划分：跳变0次—2个，跳变1次—0个，跳变2次—56个，跳变3次—0个，跳变4次—140个，跳变5次—0个，跳变6次—56个，跳变7次—0个，跳变8次—2个。共9种跳变情况，将这256个值进行分配，跳变小于2次的为等价模式类，共58个，他们对应的值按照从小到大分别编码为1—58，即它们在LBP特征图像中的灰度值为1—58，而除了等价模式类之外的混合模式类被编码为0，即它们在LBP特征中的灰度值为0，因此等价模式LBP特征图像整体偏暗。

    //等价模式LBP特征计算
    template <typename _tp>
    void getUniformPatternLBPFeature(InputArray _src,OutputArray _dst,int radius,int neighbors)
    {
        Mat src = _src.getMat();
        //LBP特征图像的行数和列数的计算要准确
        _dst.create(src.rows-2*radius,src.cols-2*radius,CV_8UC1);
        Mat dst = _dst.getMat();
        dst.setTo(0);
        //LBP特征值对应图像灰度编码表，直接默认采样点为8位
        uchar temp = 1;
        uchar table[256] = {0};
        for(int i=0;i<256;i++)
        {
            if(getHopTimes(i)<3)
            {
                table[i] = temp;
                temp++;
            }
        }
        //是否进行UniformPattern编码的标志
        bool flag = false;
        //计算LBP特征图
        for(int k=0;k<neighbors;k++)
        {
            if(k==neighbors-1)
            {
                flag = true;
            }
            //计算采样点对于中心点坐标的偏移量rx，ry
            float rx = static_cast<float>(radius * cos(2.0 * CV_PI * k / neighbors));
            float ry = -static_cast<float>(radius * sin(2.0 * CV_PI * k / neighbors));
            //为双线性插值做准备
            //对采样点偏移量分别进行上下取整
            int x1 = static_cast<int>(floor(rx));
            int x2 = static_cast<int>(ceil(rx));
            int y1 = static_cast<int>(floor(ry));
            int y2 = static_cast<int>(ceil(ry));
            //将坐标偏移量映射到0-1之间
            float tx = rx - x1;
            float ty = ry - y1;
            //根据0-1之间的x，y的权重计算公式计算权重，权重与坐标具体位置无关，与坐标间的差值有关
            float w1 = (1-tx) * (1-ty);
            float w2 =    tx  * (1-ty);
            float w3 = (1-tx) *    ty;
            float w4 =    tx  *    ty;
            //循环处理每个像素
            for(int i=radius;i<src.rows-radius;i++)
            {
                for(int j=radius;j<src.cols-radius;j++)
                {
                    //获得中心像素点的灰度值
                    _tp center = src.at<_tp>(i,j);
                    //根据双线性插值公式计算第k个采样点的灰度值
                    float neighbor = src.at<_tp>(i+x1,j+y1) * w1 + src.at<_tp>(i+x1,j+y2) *w2 \
                        + src.at<_tp>(i+x2,j+y1) * w3 +src.at<_tp>(i+x2,j+y2) *w4;
                    //LBP特征图像的每个邻居的LBP值累加，累加通过与操作完成，对应的LBP值通过移位取得
                    dst.at<uchar>(i-radius,j-radius) |= (neighbor>center) <<(neighbors-k-1);
                    //进行LBP特征的UniformPattern编码
                    if(flag)
                    {
                        dst.at<uchar>(i-radius,j-radius) = table[dst.at<uchar>(i-radius,j-radius)];
                    }
                }
            }
        }
    }
    //计算跳变次数
    int getHopTimes(int n)
    {
        int count = 0;
        bitset<8> binaryCode = n;
        for(int i=0;i<8;i++)
        {
            if(binaryCode[i] != binaryCode[(i+1)%8])
            {
                count++;
            }
        }
        return count;
    }


## 8. MB-LBP 特征
MB-LBP特征，全称为Multiscale Block LBP，来源于论文[9]，中科院的人发明的，在Traincascade级联目标训练检测中的LBP特征使用的就是MB-LBP。 MB-LBP的原理：

![](https://img-blog.csdn.net/20160119131309328)

将图像分成一个个小块（Block），每个小块再分为一个个的小区域（类似于HOG中的cell），小区域内的灰度平均值作为当前小区域的灰度值，与周围小区域灰度进行比较形成LBP特征，生成的特征称为MB-LBP，Block大小为3*3，则小区域的大小为1，就是原始的LBP特征，上图的Block大小为9*9，小区域的大小为3*3。 不同Block提取的MB-LBP特征如图所示：

![](https://img-blog.csdn.net/20160119131324844)

    //MB-LBP特征的计算
    void getMultiScaleBlockLBPFeature(InputArray _src,OutputArray _dst,int scale)
    {
        Mat src = _src.getMat();
        Mat dst = _dst.getMat();
        //定义并计算积分图像
        int cellSize = scale / 3;
        int offset = cellSize / 2;
        Mat cellImage(src.rows-2*offset,src.cols-2*offset,CV_8UC1);
        for(int i=offset;i<src.rows-offset;i++)
        {
            for(int j=offset;j<src.cols-offset;j++)
            {
                int temp = 0;
                for(int m=-offset;m<offset+1;m++)
                {
                    for(int n=-offset;n<offset+1;n++)
                    {
                        temp += src.at<uchar>(i+n,j+m);
                    }
                }
                temp /= (cellSize*cellSize);
                cellImage.at<uchar>(i-cellSize/2,j-cellSize/2) = uchar(temp); 
            }
        }
        getOriginLBPFeature<uchar>(cellImage,dst);
    }


到此为止，还没有结束，作者对得到LBP特征又进行了均值模式编码，通过对得到的特征图求直方图，得到了LBP特征值0-255之间(0-255即直方图中的bin)的特征数量，通过对bin中的数值进行排序，通过权衡，将排序在前63位的特征值看作是等价模式类，其他的为混合模式类，总共64类，作者在论文中称之为SEMB-LBP(Statistically Effective MB-LBP )。类似于等价模式LBP，等价模式的LBP的等价模式类为58种，混合模式类1种，共59种。二者除了等价模式类的数量不同之外，主要区别在于：对等价模式类的定义不同，等价模式LBP是根据0-1的跳变次数定义的，而SEMB-LBP是通过对直方图排序得到的。当然下一步要做的就是将SEMB-LBP变为LBPH进行使用。 计算SEMB-LBP的代码:

    //求SEMB-LBP
    void SEMB_LBPFeature(InputArray _src,OutputArray _dst,int scale)
    {
        Mat dst=_dst.getMat();
        Mat MB_LBPImage;
        getMultiScaleBlockLBPFeature(_src,MB_LBPImage,scale);
        //imshow("dst",dst);
        Mat histMat;
        int histSize = 256;
        float range[] = {float(0),float(255)};
        const float* ranges = {range};
        //计算LBP特征值0-255的直方图
        calcHist(&MB_LBPImage,1,0,Mat(),histMat,1,&histSize,&ranges,true,false);
        histMat.reshape(1,1);
        vector<float> histVector(histMat.rows*histMat.cols);
        uchar table[256];
        memset(table,64,256);
        if(histMat.isContinuous())
        {
            //histVector = (int *)(histMat.data);
            //将直方图histMat变为vector向量histVector
            histVector.assign((float*)histMat.datastart,(float*)histMat.dataend);
            vector<float> histVectorCopy(histVector);
            //对histVector进行排序，即对LBP特征值的数量进行排序，降序排列
            sort(histVector.begin(),histVector.end(),greater<float>());
            for(int i=0;i<63;i++)
            {
                for(int j=0;j<histVectorCopy.size();j++)
                {
                    if(histVectorCopy[j]==histVector[i])
                    {
                        //得到类似于Uniform的编码表
                        table[j]=i;
                    }
                }
            }
        }
        dst = MB_LBPImage;
        //根据编码表得到SEMB-LBP
        for(int i=0;i<dst.rows;i++)
        {
            for(int j=0;j<dst.cols;j++)
            {
                dst.at<uchar>(i,j) = table[dst.at<uchar>(i,j)];
            }
        }
    }


## 9. LBPH ——图像的 LBP 特征向量 (把 LBP 特征转化成特征向量)
LBPH，Local Binary Patterns Histograms，即LBP特征的统计直方图，LBPH将LBP特征与图像的空间信息结合在一起。这种表示方法由Ahonen等人在论文[3]中提出，他们将LBP特征图像分成m个局部块，并提取每个局部块的直方图，然后将这些直方图依次连接在一起形成LBP特征的统计直方图，即LBPH。 一幅图像具体的计算LBPH的过程（以Opencv中的人脸识别为例）： 

1. 计算图像的LBP特征图像，在上面已经讲过了。
1. 将LBP特征图像进行分块，Opencv中默认将LBP特征图像分成8行8列64块区域 
1. 计算每块区域特征图像的直方图cell_LBPH，将直方图进行归一化
1. 将上面计算的每块区域特征图像的直方图按分块的空间顺序依次排列成一行，形成LBP特征向量
1. 用机器学习的方法对LBP特征向量进行训练，用来检测和识别目标

Opencv的人脸识别使用的是Extended LBP：

    //计算LBP特征图像的直方图LBPH
    Mat getLBPH(InputArray _src,int numPatterns,int grid_x,int grid_y,bool normed)
    {
        Mat src = _src.getMat();
        int width = src.cols / grid_x;
        int height = src.rows / grid_y;
        //定义LBPH的行和列，grid_x*grid_y表示将图像分割成这么些块，numPatterns表示LBP值的模式种类
        Mat result = Mat::zeros(grid_x * grid_y,numPatterns,CV_32FC1);
        if(src.empty())
        {
            return result.reshape(1,1);
        }
        int resultRowIndex = 0;
        //对图像进行分割，分割成grid_x*grid_y块，grid_x，grid_y默认为8
        for(int i=0;i<grid_x;i++)
        {
            for(int j=0;j<grid_y;j++)
            {
                //图像分块
                Mat src_cell = Mat(src,Range(i*height,(i+1)*height),Range(j*width,(j+1)*width));
                //计算直方图
                Mat hist_cell = getLocalRegionLBPH(src_cell,0,(numPattern-1),true);
                //将直方图放到result中
                Mat rowResult = result.row(resultRowIndex);
                hist_cell.reshape(1,1).convertTo(rowResult,CV_32FC1);
                resultRowIndex++;
            }
        }
        return result.reshape(1,1);
    }
    //计算一个LBP特征图像块的直方图
    Mat getLocalRegionLBPH(const Mat& src,int minValue,int maxValue,bool normed)
    {
        //定义存储直方图的矩阵
        Mat result;
        //计算得到直方图bin的数目，直方图数组的大小
        int histSize = maxValue - minValue + 1;
        //定义直方图每一维的bin的变化范围
        float range[] = { static_cast<float>(minValue),static_cast<float>(maxValue + 1) };
        //定义直方图所有bin的变化范围
        const float* ranges = { range };
        //计算直方图，src是要计算直方图的图像，1是要计算直方图的图像数目，0是计算直方图所用的图像的通道序号，从0索引
        //Mat()是要用的掩模，result为输出的直方图，1为输出的直方图的维度，histSize直方图在每一维的变化范围
        //ranges，所有直方图的变化范围（起点和终点）
        calcHist(&src,1,0,Mat(),result,1,&histSize,&ranges,true,false);
        //归一化
        if(normed)
        {
            result /= (int)src.total();
        }
        //结果表示成只有1行的矩阵
        return result.reshape(1,1);
    }

# 人脸识别经典算法一 ：特征脸方法（Eigenface） #

特征脸方法基本是将人脸识别推向真正可用的第一种方法。

步骤一：获取包含M张人脸图像的集合S。在我们的例子里有25张人脸图像（虽然是25个不同人的人脸的图像，但是看着怎么不像呢，难道我有脸盲症么），如下图所示哦。每张图像可以转换成一个N维的向量（是的，没错，一个像素一个像素的排成一行就好了，至于是横着还是竖着获取原图像的像素，随你自己，只要前后统一就可以），然后把这M个向量放到一个集合S里，如下式所示。

![](https://img-blog.csdn.net/20140317204143093)

![](https://img-blog.csdn.net/20140317203151484?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc21hcnRlbXBpcmU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

步骤二：在获取到人脸向量集合S后，计算得到平均图像Ψ ，至于怎么计算平均图像，公式在下面。就是把集合S里面的向量遍历一遍进行累加，然后取平均值。得到的这个Ψ 其实还挺有意思的，Ψ 其实也是一个N维向量，如果再把它还原回图像的形式的话，可以得到如下的“平均脸”，是的没错，还他妈的挺帅啊。那如果你想看一下某计算机学院男生平均下来都长得什么样子，用上面的方法就可以了。

![](https://img-blog.csdn.net/20140317204335062)

![](https://img-blog.csdn.net/20140317204342734)

步骤三：计算每张图像和平均图像的差值Φ  ，就是用S集合里的每个元素减去步骤二中的平均值。

![](https://img-blog.csdn.net/20140317205731562)

步骤四：找到M个正交的单位向量un ，这些单位向量其实是用来描述Φ  （步骤三中的差值）分布的。un 里面的第k（k=1,2,3...M)个向量uk 是通过下式计算的，

![](https://img-blog.csdn.net/20140317210242218)

当这个λk（原文里取了个名字叫特征值）取最小的值时，uk  基本就确定了。补充一下，刚才也说了，这M个向量是相互正交而且是单位长度的，所以啦，uk  还要满足下式：

![](https://img-blog.csdn.net/20140317210836296)

上面的等式使得uk 为单位正交向量。计算上面的uk 其实就是计算如下协方差矩阵的特征向量：

![](https://img-blog.csdn.net/20140317213806390)

其中

![](https://img-blog.csdn.net/20140317213844796)

对于一个NxN（比如100x100）维的图像来说，上述直接计算其特征向量计算量实在是太大了（协方差矩阵可以达到10000x10000），所以有了如下的简单计算。

步骤四另解：如果训练图像的数量小于图像的维数比如（M<N^2)，那么起作用的特征向量只有M-1个而不是N^2个（因为其他的特征向量对应的特征值为0），所以求解特征向量我们只需要求解一个NxN的矩阵。这个矩阵就是步骤四中的AAT ，我们可以设该矩阵为L，那么L的第m行n列的元素可以表示为：

![](https://img-blog.csdn.net/20140330222139078)

一旦我们找到了L矩阵的M个特征向量vl，那么协方差矩阵的特征向量ul就可以表示为：

![](https://img-blog.csdn.net/20140330222145343)

这些特征向量如果还原成像素排列的话，其实还蛮像人脸的，所以称之为特征脸（如下图）。图里有二十五个特征脸，数量上和训练图像相等只是巧合。有论文表明一般的应用40个特征脸已经足够了。论文Eigenface for recognition里只用了7个特征脸来表明实验。

![](https://img-blog.csdn.net/20140330222856437)

步骤五：识别人脸。OK，终于到这步了，别绕晕啦，上面几步是为了对人脸进行降维找到表征人脸的合适向量的。首先考虑一张新的人脸，我们可以用特征脸对其进行标示：

![](https://img-blog.csdn.net/20140330223831406)

其中k=1,2...M,对于第k个特征脸uk，上式可以计算其对应的权重，M个权重可以构成一个向量：

![](https://img-blog.csdn.net/20140330223845875)

perfect，这就是求得的特征脸对人脸的表示了！

那如何对人脸进行识别呢，看下式：

![](https://img-blog.csdn.net/20140330224548625)

其中Ω代表要判别的人脸，Ωk代表训练集内的某个人脸，两者都是通过特征脸的权重来表示的。式子是对两者求欧式距离，当距离小于阈值时说明要判别的脸和训练集内的第k个脸是同一个人的。当遍历所有训练集都大于阈值时，根据距离值的大小又可分为是新的人脸或者不是人脸的两种情况。根据训练集的不同，阈值设定并不是固定的。


# 人脸识别经典算法二 ：LBP方法 #

LBP（Local Binary Patterns，局部二值模式）是提取局部特征作为判别依据的。LBP方法显著的优点是对光照不敏感，但是依然没有解决姿态和表情的问题。不过相比于特征脸方法，LBP的识别率已经有了很大的提升。

## 1、LBP特征提取 ##

最初的LBP是定义在像素3x3邻域内的，以邻域中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，3x3邻域内的8个点经比较可产生8位二进制数（通常转换为十进制数即LBP码，共256种），即得到该邻域中心像素点的LBP值，并用这个值来反映该区域的纹理信息。如下图所示：

![](https://img-blog.csdn.net/20140409100451171)


用比较正式的公式来定义的话：

![](https://img-blog.csdn.net/20140409102028328)

其中![](https://img-blog.csdn.net/20140409102051484)代表3x3邻域的中心元素，它的像素值为ic，ip代表邻域内其他像素的值。s(x)是符号函数，定义如下：

![](https://img-blog.csdn.net/20140409102057984)

### LBP的改进版本 ###

###（1）圆形LBP算子  ###

基本的 LBP算子的最大缺陷在于它只覆盖了一个固定半径范围内的小区域，这显然不能满足不同尺寸和频率纹理的需要。为了适应不同尺度的纹理特征，并达到灰度和旋转不变性的要求，Ojala等对 LBP 算子进行了改进，将 3×3邻域扩展到任意邻域，并用圆形邻域代替了正方形邻域，改进后的 LBP 算子允许在半径为 R 的圆形邻域内有任意多个像素点。从而得到了诸如半径为R的圆形区域内含有P个采样点的LBP算子。比如下图定了一个5x5的邻域：

![](https://img-blog.csdn.net/20140409101523156)

上图内有八个黑色的采样点，每个采样点的值可以通过下式计算：

![](https://img-blog.csdn.net/20140409102819171)

其中![](https://img-blog.csdn.net/20140409102904234)为邻域中心点，![](https://img-blog.csdn.net/20140409102917984)为某个采样点。通过上式可以计算任意个采样点的坐标，但是计算得到的坐标未必完全是整数，所以可以通过双线性插值来得到该采样点的像素值：

![](https://img-blog.csdn.net/20140409103242671)

### （2）LBP等价模式 ###

一个LBP算子可以产生不同的二进制模式，对于半径为R的圆形区域内含有P个采样点的LBP算子将会产生2^P种模式。很显然，随着邻域集内采样点数的增加，二进制模式的种类是急剧增加的。例如：5×5邻域内20个采样点，有2 20＝1,048,576种二进制模式。如此多的二值模式无论对于纹理的提取还是对于纹理的识别、分类及信息的存取都是不利的。同时，过多的模式种类对于纹理的表达是不利的。例如，将LBP算子用于纹理分类或人脸识别时，常采用LBP模式的统计直方图来表达图像的信息，而较多的模式种类将使得数据量过大，且直方图过于稀疏。因此，需要对原始的LBP模式进行降维，使得数据量减少的情况下能最好的代表图像的信息。

为了解决二进制模式过多的问题，提高统计性，Ojala提出了采用一种“等价模式”（Uniform Pattern）来对LBP算子的模式种类进行降维。Ojala等认为，在实际图像中，绝大多数LBP模式最多只包含两次从1到0或从0到1的跳变。因此，Ojala将“等价模式”定义为：当某个LBP所对应的循环二进制数从0到1或从1到0最多有两次跳变时，该LBP所对应的二进制就称为一个等价模式类。如00000000（0次跳变），00000111（只含一次从0到1的跳变），10001111（先由1跳到0，再由0跳到1，共两次跳变）都是等价模式类。除等价模式类以外的模式都归为另一类，称为混合模式类，例如10010111（共四次跳变）。比如下图给出了几种等价模式的示意图。

![](https://img-blog.csdn.net/20140409104010500)

通过这样的改进，二进制模式的种类大大减少，而不会丢失任何信息。模式数量由原来的2P种减少为 P ( P-1)+2种，其中P表示邻域集内的采样点数。对于3×3邻域内8个采样点来说，二进制模式由原始的256种减少为58种，这使得特征向量的维数更少，并且可以减少高频噪声带来的影响。

通过上述方法，每个像素都会根据邻域信息得到一个LBP值，如果以图像的形式显示出来可以得到下图，明显LBP对光照有较强的鲁棒性。

![](https://img-blog.csdn.net/20140409104518703)

## 2、LBP特征匹配 ##

如果将以上得到的LBP值直接用于人脸识别，其实和不提取LBP特征没什么区别，会造成计算量准确率等一系列问题。文献[1]中，将一副人脸图像分为7x7的子区域（如下图），并在子区域内根据LBP值统计其直方图，以直方图作为其判别特征。这样做的好处是在一定范围内避免图像没完全对准的情况，同时也对LBP特征做了降维处理。

![](https://img-blog.csdn.net/20140409105549078)

对于得到的直方图特征，有多种方法可以判别其相似性，假设已知人脸直方图为Mi​，待匹配人脸直方图为Si，那么可以通过:

(1)直方图交叉核方法

![](https://img-blog.csdn.net/20140409110315812)

该方法的介绍在博文：[http://blog.csdn.net/smartempire/article/details/23168945](http://blog.csdn.net/smartempire/article/details/23168945 "Histogram intersection(直方图交叉核,Pyramid Match Kernel)")

(2)卡方统计方法

![](https://img-blog.csdn.net/20140409110426046)

该方法的介绍在博文：[http://blog.csdn.net/smartempire/article/details/23203183](http://blog.csdn.net/smartempire/article/details/23203183 "卡方检验（Chi square statistic）")


# 人脸识别经典算法三 ：Fisherface（LDA） #

Fisherface是由Ronald Fisher发明的，想必这就是Fisherface名字由来。Fisherface所基于的LDA（Linear Discriminant Analysis，线性判别分析）理论和特征脸里用到的PCA有相似之处，都是对原有数据进行整体降维映射到低维空间的方法，LDA和PCA都是从数据整体入手而不同于LBP提取局部纹理特征。如果阅读本文有难度，可以考虑自学斯坦福公开课机器学习或者补充线代等数学知识。


## 1、数据集是二类情况 ##

通常情况下，待匹配人脸要和人脸库内的多张人脸匹配，所以这是一个多分类的情况。出于简单考虑，可以先介绍二类的情况然后拓展到多类。假设有二维平面上的两个点集x（x是包含横纵坐标的二维向量），它们的分布如下图（1）（分别以蓝点和红点表示数据）：

![](https://img-blog.csdn.net/20140410201232078)

原有数据是散布在平面上的二维数据，如果想用一维的量（比如到圆点的距离）来合理的表示而且区分开这些数据，该怎么办呢？一种有效的方法是找到一个合适的向量w（和数据相同维数），将数据投影到w上（会得到一个标量，直观的理解就是投影点到坐标原点的距离），根据投影点来表示和区分原有数据。以数学公式给出投影点到到原点的距离：​y=wTx。图（1）给出了两种w方案，w以从原点出发的直线来表示，直线上的点是原数据的投影点。直观判断右侧的w更好些，其上的投影点能够合理的区分原有的两个数据集。但是计算机不知道这些，所以必须要有确定的方法来计算这个w。

首先计算每类数据的均值（中心点）：

![](https://img-blog.csdn.net/20140410202938703)

这里的i是数据的分类个数，Ni代表某个分类下的数据点数，比如u1代表红点的中心，u2代表蓝点的中心。数据点投影到w上的中心为：

![](https://img-blog.csdn.net/20140410205707187)

如何判断向量w最佳呢，可以从两方面考虑：1、不同的分类得到的投影点要尽量分开；2、同一个分类投影后得到的点要尽量聚合。从这两方面考虑，可以定义如下公式：

![](https://img-blog.csdn.net/20140410210456125)

J(w)代表不同分类投影中心的距离，它的值越大越好。

![](https://img-blog.csdn.net/20140410211148265)

上式称之为散列值（scatter matrixs），代表同一个分类投影后的散列值，也就是投影点的聚合度，它的值越小代表投影点越聚合。

结合两个公式，第一个公式做分子另一个做分母：

![](https://img-blog.csdn.net/20140410211451859)

上式是w的函数，值越大w降维性能越好，所以下面的问题就是求解使上式取最大值的w。

把散列函数展开：

![](https://img-blog.csdn.net/20140410212047781)

可以发现除w和w^T外，剩余部分可以定义为：

![](https://img-blog.csdn.net/20140410212527375)

其实这就是原数据的散列矩阵了，对不对。对于固定的数据集来说，它的散列矩阵也是确定的。另外定义：

![](https://img-blog.csdn.net/20140410213311203)

Sw称为Within-class scatter matrix。

回到并用上面的两个定义做替换，得到：

![](https://img-blog.csdn.net/20140410213751562)

![](https://img-blog.csdn.net/20140410213805453)

展开J(w)的分子并定义SB，SB称为Between-class scatter。

![](https://img-blog.csdn.net/20140410214054796)

这样就得到了J(w)的最终表示：

![](https://img-blog.csdn.net/20140410214135703)

上式求极大值可以利用拉格朗日乘数法，不过需要限定一下分母的值，否则分子分母都变，怎么确定最好的w呢。可以令，利用拉格朗日乘数法得到：

![](https://img-blog.csdn.net/20140410215341875)

其中w是矩阵，所以求导时可以把![](https://img-blog.csdn.net/20140410215532562)当做![](https://img-blog.csdn.net/20140410215543187)。

上式两边同乘以![](https://img-blog.csdn.net/20140410215657000)可以得到：

![](https://img-blog.csdn.net/20140410215407703)

可以发现w其实就是矩阵![](https://img-blog.csdn.net/20140410215826343)的特征向量了。

通过上式求解w还是有些困难的，而且w会有多个解，考虑下式：

![](https://img-blog.csdn.net/20140411135525500)

将其带入下式：

![](https://img-blog.csdn.net/20140411135544734)

其中λw是以w为变量的数值，因为(u1-u2)^T和w是相同维数的，前者是行向量后者列向量。继续带入以前的公式：

![](https://img-blog.csdn.net/20140411135754703)

由于w扩大缩小任何倍不影响结果，所以可以约去两遍的未知常数λ和λw（存疑）：

![](https://img-blog.csdn.net/20140411140309015)

到这里，w就能够比较简单的求解了。


## 2、数据集是多类的情况 ##

这部分是本博文的核心。假设有C个人的人脸图像，每个人可以有多张图像，所以按人来分，可以将图像分为C类，这节就是要解决如何判别这C个类的问题。判别之前需要先处理下图像，将每张图像按照逐行逐列的形式获取像素组成一个向量，和第一节类似设该向量为x，设向量维数为n，设x为列向量（n行1列）。

和第一节简单的二维数据分类不同，这里的n有可能成千上万，比如100x100的图像得到的向量为10000维，所以第一节里将x投影到一个向量的方法可能不适用了，比如下图：

![](https://img-blog.csdn.net/20140411185100015)

图（2）

平面内找不到一个合适的向量，能够将所有的数据投影到这个向量而且不同类间合理的分开。所以我们需要增加投影向量w的个数（当然每个向量维数和数据是相同的，不然怎么投影呢），设w为：

![](https://img-blog.csdn.net/20140411185708687)

w1、w2等是n维的列向量，所以w是个n行k列的矩阵，这里的k其实可以按照需要随意选取，只要能合理表征原数据就好。x在w上的投影可以表示为：

![](https://img-blog.csdn.net/20140411185906140)

所以这里的y是k维的列向量。

像上一节一样，我们将从投影后的类间散列度和类内散列度来考虑最优的w，考虑图（2）中二维数据分为三个类别的情况。与第一节类似，μi依然代表类别i的中心，而Sw定义如下：

![](https://img-blog.csdn.net/20140411191151734)

其中：

![](https://img-blog.csdn.net/20140411191205687)

代表类别i的类内散列度，它是一个nxn的矩阵。

所有x的中心μ定义为：

![](https://img-blog.csdn.net/20140411191723265)

类间散列度定义和上一节有较大不同：

![](https://img-blog.csdn.net/20140411191553781)

代表的是每个类别到μ距离的加和，注意Ni代表类别i内x的个数，也就是某个人的人脸图像个数。

上面的讨论都是投影之间的各种数据，而J(w)的计算实际是依靠投影之后数据分布的，所以有：

![](https://img-blog.csdn.net/20140411192234546)

![](https://img-blog.csdn.net/20140411192240843)

![](https://img-blog.csdn.net/20140411192251421)

![](https://img-blog.csdn.net/20140411192255687)

分别代表投影后的类别i的中心，所有数据的中心，类内散列矩阵，类间散列矩阵。与上节类似J(w)可以定义为：

![](https://img-blog.csdn.net/20140411192643750)

![](https://img-blog.csdn.net/20140411192702906)

回想我们上节的公式J(w)，分子是两类中心距，分母是每个类自己的散列度。现在投影方向是多维了（好几条直线），分子需要做一些改变，我们不是求两两样本中心距之和（这个对描述类别间的分散程度没有用），而是求每类中心相对于全样本中心的散列度之和。得到：

![](https://img-blog.csdn.net/20140411220346421)

最后化为：

![](https://img-blog.csdn.net/20140411220407687)

还是求解矩阵的特征向量，然后根据需求取前k个特征值最大的特征向量。

另外还需注意：

由于SB中的（μi-μ）秩为1，所以SB的至多为C（矩阵的秩小于等于各个相加矩阵的和）。又因为知道了前C-1个μi后，最后一个μc可以用前面的μi来线性表示，因此SB的秩至多为C-1，所以矩阵的特征向量个数至多为C-1。因为C是数据集的类别，所以假设有N个人的照片，那么至多可以取到N-1个特征向量来表征原数据。

PCA里求得的特征向量都是正交的，但是这里的并不是对称的，所以求得的K个特征向量不一定正交，这是LDA和PCA最大的不同。

如前所述，如果在一个人脸集合上求得k个特征向量，还原为人脸图像的话就像下面这样：

![](https://img-blog.csdn.net/20140413105940671)

得到了k个特征向量，如何匹配某人脸和数据库内人脸是否相似呢，方法是将这个人脸在k个特征向量上做投影，得到k维的列向量或者行向量，然后和已有的投影求得欧式距离，根据阈值来判断是否匹配。


参考资料：

1、Eigenface for Recognition：http://www.cs.ucsb.edu/~mturk/Papers/jcn.pdf

2、特征脸维基百科：http://zh.wikipedia.org/wiki/%E7%89%B9%E5%BE%81%E8%84%B8

3、Eigenface_tutorial：http://www.pages.drexel.edu/~sis26/Eigenface%20Tutorial.htm

4、opencv 特征提取：https://blog.csdn.net/u011808673/article/details/80883474

5、Timo Ahonen, Abdenour Hadid：Face Recognition with Local Binary Patterns

6、目标检测的图像特征提取之（二）LBP特征

7、Jerry Lead 线性判别分析（Linear Discriminant Analysis）（一）

8、http://docs.opencv.org/modules/contrib/doc/facerec/facerec_tutorial.html
